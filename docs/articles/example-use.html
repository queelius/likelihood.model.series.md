<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="series.system.estimation.masked.data">
<title>Example of how to use series.system.estimation.masked.data package • series.system.estimation.masked.data</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.0/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.0/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Example of how to use series.system.estimation.masked.data package">
<meta property="og:description" content="series.system.estimation.masked.data">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">series.system.estimation.masked.data</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/example-use.html">Example of how to use series.system.estimation.masked.data package</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Example of how to use series.system.estimation.masked.data package</h1>
            
      
      
      <div class="d-none name"><code>example-use.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The R package <code>series.system.estimation.masked.data</code> is a
framework for estimating the parameters of latent component lifetimes
from <em>masked data</em> in a series system.</p>
<p>Install the library and other dependent packages with:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">devtools</span><span class="fu">::</span><span class="fu"><a href="https://devtools.r-lib.org/reference/remote-reexports.html" class="external-link">install_github</a></span><span class="op">(</span><span class="st">"queelius/series_system_estimation_masked_data"</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; * checking for file ‘/tmp/RtmpG2NDAV/remotes38d7e1313b9740/queelius-series_system_estimation_masked_data-3a4f5ba/DESCRIPTION’ ... OK</span>
<span class="co">#&gt; * preparing ‘series.system.estimation.masked.data’:</span>
<span class="co">#&gt; * checking DESCRIPTION meta-information ... OK</span>
<span class="co">#&gt; * checking for LF line-endings in source and make files and shell scripts</span>
<span class="co">#&gt; * checking for empty or unneeded directories</span>
<span class="co">#&gt; * building ‘series.system.estimation.masked.data_0.0.0.9000.tar.gz’</span>
<span class="fu">devtools</span><span class="fu">::</span><span class="fu"><a href="https://devtools.r-lib.org/reference/remote-reexports.html" class="external-link">install_github</a></span><span class="op">(</span><span class="st">"queelius/algebraic.mle"</span><span class="op">)</span>
<span class="fu">devtools</span><span class="fu">::</span><span class="fu"><a href="https://devtools.r-lib.org/reference/remote-reexports.html" class="external-link">install_github</a></span><span class="op">(</span><span class="st">"queelius/md.tools"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"devtools"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"tidyverse"</span><span class="op">)</span></code></pre></div>
<p>Once installed, you may load these libraries with:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://devtools.r-lib.org/" class="external-link">devtools</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://queelius.github.io/series_system_estimation_masked_data/">series.system.estimation.masked.data</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/queelius/algebraic.mle" class="external-link">algebraic.mle</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://queelius.github.io/md.tools/" class="external-link">md.tools</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org" class="external-link">tidyverse</a></span><span class="op">)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="masked-data">Masked data<a class="anchor" aria-label="anchor" href="#masked-data"></a>
</h2>
<p>Masked data is given by an i.i.d. sample of system lifetime data and
<em>plausible</em> candidate sets that contain the failed node.</p>
<p>The R package <code>series.system.estimation.masked.data</code>
contains several simulated masked data sets. For example, a series
system with <span class="math inline">\(3\)</span> exponentially
distributed component lifetimes is stored in
<code>exp_series_data_1</code>:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">exp_series_md_1</span><span class="op">)</span>
<span class="co">#&gt; Latent variables:  k t1 t2 t3 </span>
<span class="co">#&gt; <span style="color: #949494;"># A tibble: 1,000 × 8</span></span>
<span class="co">#&gt;          t     k      t1      t2     t3 x1    x2    x3   </span>
<span class="co">#&gt;      <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span></span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> 0.144       2 0.281   0.144   0.266  TRUE  TRUE  FALSE</span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> 0.010<span style="text-decoration: underline;">5</span>      1 0.010<span style="text-decoration: underline;">5</span>  0.014<span style="text-decoration: underline;">1</span>  0.063<span style="text-decoration: underline;">3</span> TRUE  FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> 0.036<span style="text-decoration: underline;">3</span>      2 0.105   0.036<span style="text-decoration: underline;">3</span>  0.545  TRUE  TRUE  FALSE</span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> 0.009<span style="text-decoration: underline;">72</span>     1 0.009<span style="text-decoration: underline;">72</span> 0.251   0.096<span style="text-decoration: underline;">0</span> TRUE  FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> 0.037<span style="text-decoration: underline;">7</span>      3 0.093<span style="text-decoration: underline;">7</span>  0.094<span style="text-decoration: underline;">3</span>  0.037<span style="text-decoration: underline;">7</span> TRUE  FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> 0.095<span style="text-decoration: underline;">8</span>      3 0.283   0.391   0.095<span style="text-decoration: underline;">8</span> FALSE TRUE  TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> 0.169       3 0.197   1.01    0.169  FALSE TRUE  TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> 0.270       3 0.322   0.371   0.270  FALSE TRUE  TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> 0.299       3 0.390   0.401   0.299  TRUE  FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;">10</span> 0.007<span style="text-decoration: underline;">94</span>     2 0.524   0.007<span style="text-decoration: underline;">94</span> 0.120  FALSE TRUE  TRUE </span>
<span class="co">#&gt; <span style="color: #949494;"># … with 990 more rows</span></span></code></pre></div>
<p>You can get help on any object in
<code>series.system.estimation.masked.data</code> using the built-in
help. For instance, to get information on the data set
<code>exp_series_md_1</code>, type <code><a href="../reference/exp_series_md_1.html">?exp_series_md_1</a></code> in your
R console.</p>
</div>
<div class="section level2">
<h2 id="statistical-model-for-masked-data">Statistical model for masked data<a class="anchor" aria-label="anchor" href="#statistical-model-for-masked-data"></a>
</h2>
<p>The principle object of study is the series system consisting of
<span class="math inline">\(m\)</span> components. We are interested in
estimating the component lifetimes from masked data in the form of
candidate sets, where the candidate sets satisfy the following set of
conditions:</p>
<ul>
<li><p>Condition <span class="math inline">\(C_1\)</span>: The index of
the failed component is in the candidate set, i.e., <span class="math inline">\(\Pr\{K_i \in C_i\} = 1\)</span>.</p></li>
<li><p>Condition <span class="math inline">\(C_2\)</span>: The
probability of <span class="math inline">\(C_i\)</span> given <span class="math inline">\(K_i\)</span> and <span class="math inline">\(T_i\)</span> is equally probable when the failed
component varies over the components in the candidate set, i.e., <span class="math inline">\(\Pr\{C_i=c_i|K_i=j,T_i=t_i\} =
\Pr\{C_i=c_i|K_i=j',T_i=t_i\}\)</span> for any <span class="math inline">\(j,j' \in c_i\)</span>.</p></li>
<li>
<p>Condition <span class="math inline">\(C_3\)</span>: The masking
probabilities are independent of <span class="math inline">\(\boldsymbol{\theta}\)</span>, i.e., <span class="math inline">\(\Pr\{C_i=c_i|K_i=j,T_i=t_i\}\)</span> is not a
function of <span class="math inline">\(\boldsymbol{\theta}\)</span>.</p>
<p>That means, whatever the generative mechanism underlying <span class="math inline">\(\mathcal{C}_1,\ldots,\mathcal{C}_n\)</span>, it
has no explicit knowledge of <span class="math inline">\(\boldsymbol{\theta}\)</span>, but the <span class="math inline">\(i\)</span> candidate set <span class="math inline">\(\mathcal{C}_i\)</span> may depend on the
realizations of <span class="math inline">\(T_{i 1},\ldots,T_{i
n}\)</span> and other factors not explicitly in the statistical model we
have described.</p>
</li>
</ul>
<div class="section level3">
<h3 id="bernoulli-candidate-model-that-satisfies-c_1-c_2-and-c_3">Bernoulli candidate model that satisfies <span class="math inline">\(C_1\)</span>, <span class="math inline">\(C_2\)</span>, and <span class="math inline">\(C_3\)</span><a class="anchor" aria-label="anchor" href="#bernoulli-candidate-model-that-satisfies-c_1-c_2-and-c_3"></a>
</h3>
<p>As long as we satisfy conditions <span class="math inline">\(C_1\)</span>, <span class="math inline">\(C_2\)</span>, and <span class="math inline">\(C_3\)</span>, our reduced likelihood function that
assumes those conditions obtains the same MLEs as the full likelihood
function.</p>
<p>In what follows, we describe our Bernoulli candidate set model that
generates candidate sets that satisfy these conditions.</p>
<pre><code><span class="co">#&gt; No documentation for 'md_bernoulli_candidate_C1_C2_C3' in specified packages and libraries</span>
<span class="co">#&gt; function (md, m, p = function(n) runif(n)) </span>
<span class="co">#&gt; {</span>
<span class="co">#&gt;     stopifnot(!is.null(md$k))</span>
<span class="co">#&gt;     n &lt;- nrow(md)</span>
<span class="co">#&gt;     stopifnot(n &gt; 0)</span>
<span class="co">#&gt;     x &lt;- matrix(NA, nrow = n, ncol = m)</span>
<span class="co">#&gt;     u &lt;- matrix(runif(m * n), nrow = n)</span>
<span class="co">#&gt;     gam &lt;- p(n)</span>
<span class="co">#&gt;     for (i in 1:n) {</span>
<span class="co">#&gt;         for (j in 1:m) {</span>
<span class="co">#&gt;             x[i, j] &lt;- ifelse(md$k[i] == j, T, u[i, j] &lt; gam[i])</span>
<span class="co">#&gt;         }</span>
<span class="co">#&gt;     }</span>
<span class="co">#&gt;     x &lt;- as_tibble(x)</span>
<span class="co">#&gt;     colnames(x) &lt;- paste0("x", 1:m)</span>
<span class="co">#&gt;     md %&gt;% bind_cols(x)</span>
<span class="co">#&gt; }</span>
<span class="co">#&gt; &lt;bytecode: 0x5586b0f6b920&gt;</span>
<span class="co">#&gt; &lt;environment: namespace:series.system.estimation.masked.data&gt;</span></code></pre>
</div>
<div class="section level3">
<h3 id="estimating-the-variance-covariance-using-the-bootstrap-method">Estimating the variance-covariance using the Bootstrap method<a class="anchor" aria-label="anchor" href="#estimating-the-variance-covariance-using-the-bootstrap-method"></a>
</h3>
<p>Alternatively, we could estimate <span class="math inline">\(\boldsymbol{\theta}\)</span> with <span class="math inline">\(B\)</span> simulated draws from the MLEs that
satisfy <span class="math display">\[
    \operatorname{argmax}_{\boldsymbol{\theta }\in \boldsymbol{\Omega}}
\ell(\boldsymbol{\theta}|\mathcal{D_i})
\]</span> where <span class="math inline">\(\mathcal{\boldsymbol{D_i}}\)</span> is a random
sample from the empirical distribution <span class="math inline">\(\{(S_i,\delta_i,C_i)\}_1^n\)</span>. We call this
the <em>Bootstrap</em>.</p>
<p>Assuming the above solution to the MLE equation is <em>unique</em>,
this gives us a single point <span class="math inline">\(\hat{\boldsymbol{\theta}}_{(i)}\)</span> when
conditioned on the simulated masked data <span class="math inline">\(\boldsymbol{D_i}\)</span>.</p>
</div>
</div>
<div class="section level2">
<h2 id="exponential-series-system">Exponential series system<a class="anchor" aria-label="anchor" href="#exponential-series-system"></a>
</h2>
<p>The most straightforward series system to estimate is the series
system with exponentially distributed component lifetimes.</p>
<p>Suppose an exponential series system with <span class="math inline">\(m\)</span> components is parameterized by <span class="math inline">\(\boldsymbol{\theta }= (3,4,5)'\)</span>. Then,
the component assigned to index <span class="math inline">\(j\)</span>
has an exponentially distributed lifetime with a failure rate <span class="math inline">\(\theta_j\)</span>, e.g., <span class="math inline">\(\theta_2 = 4\)</span> is the failure rate of the
component indexed by <span class="math inline">\(4\)</span>.</p>
<p>Let’s simulate a series system (without candidate sets):</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">300</span>
<span class="co">#theta &lt;- c(3,4,5)</span>
<span class="va">theta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>,<span class="fl">3</span>,<span class="fl">3</span><span class="op">)</span>
<span class="va">m</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span>

<span class="va">md</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span>t1<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html" class="external-link">rexp</a></span><span class="op">(</span><span class="va">n</span>,<span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,
             t2<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html" class="external-link">rexp</a></span><span class="op">(</span><span class="va">n</span>,<span class="va">theta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,
             t3<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html" class="external-link">rexp</a></span><span class="op">(</span><span class="va">n</span>,<span class="va">theta</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span>
    <span class="fu"><a href="../reference/md_series_lifetime.html">md_series_lifetime</a></span><span class="op">(</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">md</span><span class="op">)</span>
<span class="co">#&gt; <span style="color: #949494;"># A tibble: 300 × 5</span></span>
<span class="co">#&gt;         t1     t2      t3     k       t</span>
<span class="co">#&gt;      <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;int&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> 0.350   0.016<span style="text-decoration: underline;">7</span> 0.333       2 0.016<span style="text-decoration: underline;">7</span> </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> 0.018<span style="text-decoration: underline;">9</span>  0.456  0.067<span style="text-decoration: underline;">0</span>      1 0.018<span style="text-decoration: underline;">9</span> </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> 0.008<span style="text-decoration: underline;">38</span> 0.102  0.016<span style="text-decoration: underline;">4</span>      1 0.008<span style="text-decoration: underline;">38</span></span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> 0.012<span style="text-decoration: underline;">7</span>  0.435  0.356       1 0.012<span style="text-decoration: underline;">7</span> </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> 0.470   0.018<span style="text-decoration: underline;">7</span> 0.500       2 0.018<span style="text-decoration: underline;">7</span> </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> 0.081<span style="text-decoration: underline;">6</span>  0.365  0.466       1 0.081<span style="text-decoration: underline;">6</span> </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> 0.144   0.274  0.174       1 0.144  </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> 0.042<span style="text-decoration: underline;">4</span>  0.345  0.003<span style="text-decoration: underline;">51</span>     3 0.003<span style="text-decoration: underline;">51</span></span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> 0.012<span style="text-decoration: underline;">3</span>  0.172  0.015<span style="text-decoration: underline;">0</span>      1 0.012<span style="text-decoration: underline;">3</span> </span>
<span class="co">#&gt; <span style="color: #BCBCBC;">10</span> 0.281   0.061<span style="text-decoration: underline;">3</span> 0.049<span style="text-decoration: underline;">9</span>      3 0.049<span style="text-decoration: underline;">9</span> </span>
<span class="co">#&gt; <span style="color: #949494;"># … with 290 more rows</span></span></code></pre></div>
<p>In the above, we used the function <code>md_series_lifetime</code>.
To get more help on it, type <code><a href="../reference/md_series_lifetime.html">?md_series_lifetime</a></code>.</p>
<div class="section level3">
<h3 id="candidate-sets">Candidate sets<a class="anchor" aria-label="anchor" href="#candidate-sets"></a>
</h3>
<p>We simulate candidate sets using the Bernoulli candidate model with
an appropriate set of parameters to satisfy conditions <span class="math inline">\(C_1\)</span>, <span class="math inline">\(C_2\)</span>, and <span class="math inline">\(C_3\)</span>:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">md</span> <span class="op">&lt;-</span> <span class="va">md</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="../reference/md_bernoulli_candidate_C1_C2_C3.html">md_bernoulli_candidate_C1_C2_C3</a></span><span class="op">(</span><span class="va">m</span>, <span class="kw">function</span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">.5</span>,<span class="va">n</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">md</span><span class="op">)</span>
<span class="co">#&gt; <span style="color: #949494;"># A tibble: 300 × 8</span></span>
<span class="co">#&gt;         t1     t2      t3     k       t x1    x2    x3   </span>
<span class="co">#&gt;      <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;int&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span></span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> 0.350   0.016<span style="text-decoration: underline;">7</span> 0.333       2 0.016<span style="text-decoration: underline;">7</span>  TRUE  TRUE  FALSE</span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> 0.018<span style="text-decoration: underline;">9</span>  0.456  0.067<span style="text-decoration: underline;">0</span>      1 0.018<span style="text-decoration: underline;">9</span>  TRUE  FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> 0.008<span style="text-decoration: underline;">38</span> 0.102  0.016<span style="text-decoration: underline;">4</span>      1 0.008<span style="text-decoration: underline;">38</span> TRUE  FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> 0.012<span style="text-decoration: underline;">7</span>  0.435  0.356       1 0.012<span style="text-decoration: underline;">7</span>  TRUE  TRUE  FALSE</span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> 0.470   0.018<span style="text-decoration: underline;">7</span> 0.500       2 0.018<span style="text-decoration: underline;">7</span>  FALSE TRUE  TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> 0.081<span style="text-decoration: underline;">6</span>  0.365  0.466       1 0.081<span style="text-decoration: underline;">6</span>  TRUE  FALSE FALSE</span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> 0.144   0.274  0.174       1 0.144   TRUE  FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> 0.042<span style="text-decoration: underline;">4</span>  0.345  0.003<span style="text-decoration: underline;">51</span>     3 0.003<span style="text-decoration: underline;">51</span> FALSE FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> 0.012<span style="text-decoration: underline;">3</span>  0.172  0.015<span style="text-decoration: underline;">0</span>      1 0.012<span style="text-decoration: underline;">3</span>  TRUE  FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;">10</span> 0.281   0.061<span style="text-decoration: underline;">3</span> 0.049<span style="text-decoration: underline;">9</span>      3 0.049<span style="text-decoration: underline;">9</span>  TRUE  TRUE  TRUE </span>
<span class="co">#&gt; <span style="color: #949494;"># … with 290 more rows</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="log-likelihood-of-theta-given-masked-data">Log-likelihood of <span class="math inline">\(\theta\)</span> given
masked data<a class="anchor" aria-label="anchor" href="#log-likelihood-of-theta-given-masked-data"></a>
</h3>
<p>The reduced log-likelihood function (the log of the kernel of the
likelihood function) is given by <span class="math display">\[
\ell(\theta) =
    -\left(\sum_{i=1}^{n} t_i\right)
    \left(\sum_{j=1}^{m} \theta_j\right) +
    \sum_{i=1}^{n} \log\left(\sum_{j \in c_i} \theta_j\right).
\]</span></p>
<p>The following log-likelihood constructor,
<code>md_loglike_exp_series_C1_C2_c3</code>, is implemented using
minimally sufficient statistics, which significantly improves the
computational efficiency of computing the log-likelihood.</p>
<p>We compute the log-likelihood function as a function of the masked
data <code>md</code> with:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">l</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/md_loglike_exp_series_C1_C2_C3.html">md_loglike_exp_series_C1_C2_C3</a></span><span class="op">(</span><span class="va">md</span><span class="op">)</span></code></pre></div>
<p>The log-likelihood function contains the maximum amount of
information about parameter <span class="math inline">\(\boldsymbol{\theta}\)</span> given the sample of
masked data <code>md</code> satisfying conditions <span class="math inline">\(C_1\)</span>, <span class="math inline">\(C_2\)</span>, and <span class="math inline">\(C_3\)</span>.</p>
<p>Suppose we do not know that <span class="math inline">\(\boldsymbol{\theta }= (3,4,5)'\)</span>. With
the log-likelihood, we may estimate <span class="math inline">\(\theta\)</span> with <span class="math inline">\(\hat\theta\)</span> by solving <span class="math display">\[
\hat{\boldsymbol{\theta}} = \operatorname{argmax}_{\boldsymbol{\theta
}\in \Omega} \ell(\theta),
\]</span> i.e., finding the point that <em>maximizes</em> the
log-likelihood on the observed sample <code>md</code>. This is known as
<em>maximum likelihood estimation</em> (MLE). We typically solve for the
MLE by solving <span class="math display">\[
\nabla \ell|_{\boldsymbol{\theta}=\hat{\boldsymbol{\theta}}} =
\boldsymbol{0}.
\]</span> We use the iterative method known as the gradient ascent to
solve this, <span class="math display">\[
\boldsymbol{\theta}^{(n+1)} = \boldsymbol{\theta}^n + \alpha_n \nabla
\ell(\boldsymbol{\theta}^n),
\]</span> where <span class="math inline">\(\alpha_n\)</span> is chosen
to approximately maximize <span class="math inline">\(\ell(\theta^{(n+1))}\)</span> by using
backtracking line search.</p>
<p>The function <code>md_mle_exp_series_C1_C2_C3</code> is a small
wrapper for this function, providing <code>mle_gradient_ascent</code>
with the appropriate arguments. We find <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> by running the
following R code:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">mle</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/md_mle_exp_series_C1_C2_C3.html">md_mle_exp_series_C1_C2_C3</a></span><span class="op">(</span><span class="va">md</span>,theta0<span class="op">=</span><span class="va">theta</span><span class="op">)</span>
<span class="va">theta.hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://queelius.github.io/algebraic.mle/reference/point.html" class="external-link">point</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span>
<span class="co">#&gt; Maximum likelihood estimator, of type mle_numerical ,</span>
<span class="co">#&gt; is normally distributed with mean</span>
<span class="co">#&gt; [1] 2.50 2.77 4.23</span>
<span class="co">#&gt; and variance-covariance</span>
<span class="co">#&gt;         [,1]    [,2]    [,3]</span>
<span class="co">#&gt; [1,]  0.1845 -0.0571 -0.0483</span>
<span class="co">#&gt; [2,] -0.0571  0.2005 -0.0555</span>
<span class="co">#&gt; [3,] -0.0483 -0.0555  0.2379</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; The asymptotic mean squared error 0.623 </span>
<span class="co">#&gt; The asymptotic 95% confidence interval is</span>
<span class="co">#&gt;   2.5 % 97.5 %</span>
<span class="co">#&gt; 1  1.79   3.20</span>
<span class="co">#&gt; 2  2.04   3.51</span>
<span class="co">#&gt; 3  3.43   5.04</span>
<span class="co">#&gt; The log-likelihood is 236 </span>
<span class="co">#&gt; The AIC is -465</span></code></pre></div>
<p>The function <code>md_mle_exp_series_C1_C2_C3</code> returns an
<code>md_mle</code> object, which has various methods implemented for
it, e.g., <code>confint</code> (computes the estimators confidence
interval). In the above, we see use of the <code>summary</code> method,
which takes an <code>mle</code> object and prints out a summary of its
properties. We let <code>theta.hat</code> be given by the
<code>point</code> method, which obtains the <em>best</em> the MLE <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>.</p>
<p>We see that <span class="math inline">\(\hat{\boldsymbol{\theta}} =
(2.498, 2.775, 4.233)\)</span>. If we let the third argument in the
log-likelihood function be fixed at <span class="math inline">\(\hat\theta_3 = 4.233)\)</span>, then we may
profile the log-likelihood function over the first two parameters:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">prof</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta1</span><span class="op">)</span> <span class="op">{</span> <span class="fu">l</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">theta1</span>,<span class="va">theta.hat</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,<span class="va">theta.hat</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op">}</span>
<span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="va">theta.hat</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">-</span><span class="fl">2</span>,<span class="va">theta.hat</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">+</span><span class="fl">2</span>,<span class="fl">.05</span><span class="op">)</span><span class="op">)</span>
<span class="va">data</span><span class="op">$</span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span>
    <span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">prof</span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span>
<span class="va">data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">x</span>,y<span class="op">=</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">theta.hat</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,<span class="fu">prof</span><span class="op">(</span><span class="va">theta.hat</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p><img src="example-use_files/figure-html/unnamed-chunk-9-1.png" width="700"></p>
<p>Due to sampling variability, different runs of the experiment will
result in different outcomes, i.e., <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> has a sampling
distribution. We see that <span class="math inline">\(\hat{\boldsymbol{\theta}} \neq
\boldsymbol{\theta}\)</span>, but it is reasonably close. We may measure
this sampling variability using the variance-covariance matrix, bias,
mean squared error (MSE), and confidence intervals.</p>
</div>
<div class="section level3">
<h3 id="sampling-distribution-of-the-mle">Sampling distribution of the MLE<a class="anchor" aria-label="anchor" href="#sampling-distribution-of-the-mle"></a>
</h3>
<p>The MLE <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> as a function
of a random sample of masked data, and is thus a random vector.
Theoretically, <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> converges in
distribution to the multivariate normal with a mean <span class="math inline">\(\boldsymbol{\theta}\)</span> and we may estimate
the variance-covariance with the inverse of the observed Fisher matrix,
which is given by <span class="math display">\[
    J(\hat{\boldsymbol{\theta}}) = -\nabla^2
l|_{\hat{\boldsymbol{\theta}}}.
\]</span> Thus, <span class="math display">\[
    \hat{\boldsymbol{\theta}} \sim
\mathcal{N}(\boldsymbol{\theta},J^{-1}(\hat{\boldsymbol{\theta}})).
\]</span></p>
<p>Asymptotically, <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> is the UMVUE,
i.e., it is unbiased and obtains the minimum sampling variance. An
estimate of the variance-covariance may be obtained with:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="op">(</span><span class="va">V.hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/vcov.html" class="external-link">vcov</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<table class="table"><tbody>
<tr class="odd">
<td align="right">0.185</td>
<td align="right">-0.057</td>
<td align="right">-0.048</td>
</tr>
<tr class="even">
<td align="right">-0.057</td>
<td align="right">0.200</td>
<td align="right">-0.055</td>
</tr>
<tr class="odd">
<td align="right">-0.048</td>
<td align="right">-0.055</td>
<td align="right">0.238</td>
</tr>
</tbody></table>
</div>
<div class="section level3">
<h3 id="bias-and-mean-squared-error">Bias and mean squared error<a class="anchor" aria-label="anchor" href="#bias-and-mean-squared-error"></a>
</h3>
<p>We would like to measure the accuracy and precision of <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>. In statistical
literature, the bias <span class="math display">\[
\operatorname{b}(\hat{\boldsymbol{\theta}}) =
E(\hat{\boldsymbol{\theta}}) - \boldsymbol{\theta}
\]</span> is a measure of accuracy and variance is a measure of
precision.</p>
<p>The mean squared error, denoted by <span class="math inline">\(\operatorname{MSE}\)</span>, is a measure of
estimator error that incorporates both the bias and the variance, <span class="math display">\[
\operatorname{MSE}(\hat{\boldsymbol{\theta}}) =
    \operatorname{trace}\bigl(\operatorname{vcov}(\hat{\boldsymbol{\theta}})\bigr)
+
    \operatorname{b}^2(\hat{\boldsymbol{\theta}}).
\]</span></p>
<p>Since <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>
is asymptotically unbiased and minimum variance, <span class="math display">\[
\lim_{n \to \infty} \operatorname{MSE}(\hat{\boldsymbol{\theta}}) =
    \operatorname{trace}\bigl(\operatorname{vcov}(\hat{\boldsymbol{\theta}})\bigr).
\]</span> Thus, for sufficiently large samples, <span class="math inline">\(\operatorname{MSE}(\hat{\boldsymbol{\theta}})\)</span>
is approximately given by the <code>trace</code> of the estimated
variance-covariance matrix:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="op">(</span><span class="va">mse</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="va">V.hat</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.623</span></code></pre></div>
<p>If we have a sample of <span class="math inline">\(n\)</span> MLEs,
<span class="math inline">\(\hat{\boldsymbol{\theta}}^{(1)},\ldots,\hat{\boldsymbol{\theta}}^{(n)}\)</span>,
then we may estimate both the bias and the MSE respectively with the
statistics <span class="math display">\[
\hat{\operatorname{b}} = \frac{1}{n} \sum_{i=1}
\hat{\boldsymbol{\theta}}^{(i)} - \boldsymbol{\theta}
\]</span> and <span class="math display">\[
\widehat{\operatorname{MSE}} = \frac{1}{n}
    \sum_{i=1}^n (\hat{\boldsymbol{\theta}}^{(i)} - \boldsymbol{\theta})
                 (\hat{\boldsymbol{\theta}}^{(i)} -
\boldsymbol{\theta})'.
\]</span> We may then compare these statistics, <span class="math inline">\(\hat{\operatorname{b}}\)</span> and <span class="math inline">\(\widehat{\operatorname{MSE}}\)</span>, with the
asymptotic bias <span class="math inline">\((\boldsymbol{0})\)</span>
and the asymptotic <span class="math inline">\(\operatorname{MSE}\)</span>.</p>
<p>Let us compute estimates of the bias and mean squared error as a
function of sample size <span class="math inline">\(n\)</span>:</p>
<p><img src="example-use_files/figure-html/unnamed-chunk-12-1.png" width="480"></p>
<p>A primary statistic is the <em>confidence interval</em>. A <span class="math inline">\((1-\alpha)100\%\)</span> confidence interval for
<span class="math inline">\(\theta_j\)</span> may be estimated with
<span class="math inline">\(\hat\theta_j \pm z_{1-\alpha/2}
\sqrt{\hat{V}_{j j}}\)</span>. We provide a method for doing this
calculation:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html" class="external-link">as_tibble</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>length<span class="op">=</span><span class="va">.</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="op">-</span><span class="va">.</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<table class="table">
<thead><tr class="header">
<th align="right">2.5 %</th>
<th align="right">97.5 %</th>
<th align="right">length</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">1.79</td>
<td align="right">3.21</td>
<td align="right">1.41</td>
</tr>
<tr class="even">
<td align="right">2.04</td>
<td align="right">3.51</td>
<td align="right">1.47</td>
</tr>
<tr class="odd">
<td align="right">3.43</td>
<td align="right">5.04</td>
<td align="right">1.60</td>
</tr>
</tbody>
</table>
<p>How does this compare to the confidence intervals given that the
candidate sets are generated using the Bernoulli candidate model with a
different choice of parameters? First, we generate a new MLE using a
different sample of masked data, <code>new.md</code>:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">new.md</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span>
    t1<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html" class="external-link">rexp</a></span><span class="op">(</span>n<span class="op">=</span><span class="va">n</span>,rate<span class="op">=</span><span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,
    t2<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html" class="external-link">rexp</a></span><span class="op">(</span>n<span class="op">=</span><span class="va">n</span>,rate<span class="op">=</span><span class="va">theta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,
    t3<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html" class="external-link">rexp</a></span><span class="op">(</span>n<span class="op">=</span><span class="va">n</span>,rate<span class="op">=</span><span class="va">theta</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span>
    <span class="fu"><a href="../reference/md_series_lifetime.html">md_series_lifetime</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span>
    <span class="fu"><a href="../reference/md_bernoulli_candidate_C1_C2_C3.html">md_bernoulli_candidate_C1_C2_C3</a></span><span class="op">(</span>m<span class="op">=</span><span class="fl">3</span>,p<span class="op">=</span><span class="kw">function</span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">.5</span>,<span class="va">n</span><span class="op">)</span><span class="op">)</span>
<span class="va">mle.new</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/md_mle_exp_series_C1_C2_C3.html">md_mle_exp_series_C1_C2_C3</a></span><span class="op">(</span><span class="va">new.md</span>,<span class="va">theta</span><span class="op">)</span></code></pre></div>
<p>Let’s compare the lengths of the confidence intervals:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html" class="external-link">as_tibble</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>length<span class="op">=</span><span class="va">.</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="op">-</span><span class="va">.</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<table class="table">
<thead><tr class="header">
<th align="right">2.5 %</th>
<th align="right">97.5 %</th>
<th align="right">length</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">1.79</td>
<td align="right">3.21</td>
<td align="right">1.41</td>
</tr>
<tr class="even">
<td align="right">2.04</td>
<td align="right">3.51</td>
<td align="right">1.47</td>
</tr>
<tr class="odd">
<td align="right">3.43</td>
<td align="right">5.04</td>
<td align="right">1.60</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html" class="external-link">as_tibble</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">mle.new</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>length<span class="op">=</span><span class="va">.</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="op">-</span><span class="va">.</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<table class="table">
<thead><tr class="header">
<th align="right">2.5 %</th>
<th align="right">97.5 %</th>
<th align="right">length</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">1.88</td>
<td align="right">3.21</td>
<td align="right">1.33</td>
</tr>
<tr class="even">
<td align="right">2.81</td>
<td align="right">4.25</td>
<td align="right">1.43</td>
</tr>
<tr class="odd">
<td align="right">2.20</td>
<td align="right">3.50</td>
<td align="right">1.30</td>
</tr>
</tbody>
</table>
<p>We see that the lengths of the confidence intervals are significantly
shorter.</p>
<p>If <em>no</em> information is provided about the component cause of
failure in a series system with <span class="math inline">\(m\)</span>
components, then the <span class="math inline">\(m_0\)</span> estimator
is not unique and does not converge to <span class="math inline">\(\boldsymbol{\theta}\)</span>.</p>
<div class="section level4">
<h4 id="sampling-distribution-of-the-mle-1">Sampling distribution of the MLE<a class="anchor" aria-label="anchor" href="#sampling-distribution-of-the-mle-1"></a>
</h4>
<p>We know that <span class="math display">\[
\hat{\boldsymbol{\theta}} \sim
\mathcal{N}\bigl(\boldsymbol{\theta},J^{-1}(\boldsymbol{\theta})\bigr).
\]</span> We can estimate the sampling distribution of <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> with <span class="math inline">\(\mathcal{N}\bigl(\hat\theta,J^{-1}(\hat{\boldsymbol{\theta}})\bigr)\)</span>.
This makes it trivial to estimate any other function of <span class="math inline">\(\boldsymbol{\theta}\)</span> by sampling from the
approximation:</p>
<p>In Figure 2, we show contour plots of the first two components for
the MLE sample.</p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="estimating-component-cause">Estimating component cause<a class="anchor" aria-label="anchor" href="#estimating-component-cause"></a>
</h2>
<p>Another characteristic we may wish to estimate is the probability
that a particular component in an observation caused the system
failure.</p>
<p>We wish to use as much information as possible to do this estimation.
We consider three cases:</p>
<ol style="list-style-type: decimal">
<li><p>We have masked data <code>md</code> with candidate sets and
system failure times and seek to estimate the node failure probabilities
of observations in this data. This case provides the most accurate
estimates of the node probability failures, as have both system failure
times and candidate sets as predictors of the node failure.</p></li>
<li><p>We have a new observation of a system failure time and an
estimate of <span class="math inline">\(\theta\)</span> from
<code>md</code>. In this case, we cannot condition on candidate sets,
since the observation does not include that information. However, we do
have a system failure time.</p></li>
<li><p>We have an estimate of <span class="math inline">\(\boldsymbol{\theta}\)</span> from <code>md</code>
but wish to predict the node failure of a system that has failed, but we
do not know when it failed.</p></li>
</ol>
<p>We consider case 1 described above where we have masked data
<code>md</code> that includes both candidate sets and system failure
times.</p>
<p>In this case, we are interested in <span class="math display">\[
    f_{K_i|C_i,T_i}(j|c_i,t_i,\boldsymbol{\theta}) =
\frac{h_j(t;\boldsymbol{\theta_k})}{\sum_{j' \in c_i}
h_{j'}(t_i;\boldsymbol{\theta_{j'}})},
\]</span> which in the exponential series case simplifies to <span class="math display">\[
    f_{K_i|C_,T_i}(j|c_i,t_i,\boldsymbol{\theta}) =
\frac{\boldsymbol{\theta_j}}{\sum_{j' \in c_i}
\boldsymbol{\theta_{j'}}}.
\]</span></p>
<p>We decorate <code>md</code> with this probability distribution with
the decorator function
<code>md_series_component_failure_probability</code>, which accepts
masked data as input and returns the masked data with columns for
component cause of failure probabilities given by
<code>k1</code>,…,<code>km</code>.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#h &lt;- list(function(t) theta.hat[1],</span>
<span class="co">#          function(t) theta.hat[2],</span>
<span class="co">#          function(t) theta.hat[3])</span>
<span class="co">#md %&gt;% md_series_component_failure_probability_decorator(h)</span></code></pre></div>
<p>We notice that every row over the columns <code>k1</code>,
<code>k2</code>, and <code>k3</code> given a specific candidate set are
the same. This is as expected, since in the case of the exponential
series, the component failure rates are constant with respect to system
failure time.</p>
<p>If we already had an estimate of <span class="math inline">\(\boldsymbol{\theta}\)</span> and we sought to
predict the failed components from only system lifetime data, we would
just let the candidate sets contain all of the component indexes.</p>
<p>Also, observe that the component failure probabilities <span class="math display">\[
    \hat{\boldsymbol{k}}_i(\boldsymbol{\theta}) =
(\hat{k}_1,\hat{k}_2,\hat{k}_3)'
\]</span> is a random vector whose sampling distribution under the right
conditions is a multivariate normal whose <span class="math inline">\(j\)</span> component is given by <span class="math display">\[
    \hat{k}_j \sim
\mathcal{N}(f_{K_i|T_i}(j|t_i,\boldsymbol{\theta}),\boldsymbol{\Sigma}_i).
\]</span> We can simulate <span class="math inline">\(n\)</span> draws
from <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> and
then apply the above statistic of interest, generating the data <span class="math display">\[
    \hat{\boldsymbol{k}}^{(1)},\ldots,\hat{\boldsymbol{k}}^{(n)}.
\]</span></p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Alexander Towell.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.3.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
